apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: benchmark
  namespace: spark
spec:
  type: Scala
  mode: cluster
  sparkVersion: 3.2.1
  image: rg.fr-par.scw.cloud/benchmark-spark/benchmark:1.0
  imagePullPolicy: Always
  mainClass: ked.Benchmark
  mainApplicationFile: local:///opt/spark/examples/jars/spark-benchmark.jar
  sparkConf:
    spark.eventLog.enabled: "true"
    spark.eventLog.dir: s3a://datalake-benchmark-spark/spark-history-server/
  hadoopConf:
    mapreduce.fileoutputcommitter.algorithm.version: "2"
  driver:
    env:
      - name: REGION
        value: "fr-par"
      - name: INPUT
        value: "s3a://datalake-benchmark-spark/data/clean/TPC-DS/10TB/"
      - name: OUTPUT
        value: "s3a://datalake-benchmark-spark/data/results"
      - name: EXPERIMENT_NAME
        value: "tpcds-none"
      - name: QUERY_MODE
        value: "tpcds"
      - name: OUTPUT_MODE
        value: "none"
    envFrom:
      - secretRef:
          name: scw-secrets
    cores: 1
    memory: "1024m"
    hostNetwork: true
    labels:
      version: 3.2.1
    serviceAccount: spark-kube
  executor:
    serviceAccount: spark-kube
    env:
      - name: REGION
        value: "fr-par"
      - name: INPUT
        value: "s3a://datalake-benchmark-spark/data/clean/TPC-DS/10TB/"
      - name: OUTPUT
        value: "s3a://datalake-benchmark-spark/data/results"
      - name: EXPERIMENT_NAME
        value: "test"
      - name: QUERY_MODE
        value: "test"
      - name: OUTPUT_MODE
        value: "none"
    envFrom:
      - secretRef:
          name: scw-secrets
    cores: 5
    instances: 35
    memory: "28g"
