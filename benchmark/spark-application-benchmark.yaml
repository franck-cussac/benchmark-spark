apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: benchmark
  namespace: spark
spec:
  type: Scala
  mode: cluster
  sparkVersion: 3.3.0
  image: public.ecr.aws/hymaia/benchmark:3.3
  imagePullPolicy: Always
  mainClass: hymaia.Benchmark
  mainApplicationFile: local:///opt/spark/examples/jars/spark-benchmark.jar
  sparkConf:
    spark.eventLog.enabled: "true"
    spark.eventLog.dir: s3a://dev-hyma-kube-datalake/spark-history-server/
  hadoopConf:
    "fs.s3a.aws.credentials.provider": "com.amazonaws.auth.WebIdentityTokenCredentialsProvider"
    "fs.s3a.committer.magic.enabled": "true"
    "fs.s3a.committer.name": "magic"
    "mapreduce.outputcommitter.factory.scheme.s3a": "org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory"
    "spark.sql.sources.commitProtocolClass": "org.apache.spark.internal.io.cloud.PathOutputCommitProtocol"
    "spark.sql.parquet.output.committer.class": "org.apache.spark.internal.io.cloud.BindingParquetOutputCommitter"
    "mapreduce.fileoutputcommitter.algorithm.version": "2"
  driver:
    env:
      - name: INPUT
        value: "s3a://dev-hyma-kube-datalake/data/raw/TPC-DS/10TB/"
      - name: OUTPUT
        value: "s3a://dev-hyma-kube-datalake/output"
      - name: EXPERIMENT_NAME
        value: "tpcds-magic"
      - name: QUERY_MODE
        value: "tpcds"
      - name: OUTPUT_MODE
        value: "parquet"
    cores: 3
    memory: "12g"
    labels:
      version: 3.3.0
    serviceAccount: spark-kube
  executor:
    serviceAccount: spark-kube
    cores: 3
    instances: 10
    memory: "12g"
